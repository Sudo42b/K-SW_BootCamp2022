{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 YOLO(You Only Look Once)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*bSLNlG7crv-p-m4LVYYk3Q.png\" width=400>\n",
    "\n",
    "- 가장 빠른 객체 검출 알고리즘 중 하나\n",
    "- Single-Stage Detection으로 기존의 detection 모델들에 비해 처리과정이 간단하기 때문에 학습과 예측의 속도가 빠름\n",
    "- 모든 학습 과정이 이미지 전체를 통해 일어나기 때문에 단일 대상의 특징뿐 아니라 이미지 전체의 맥락을 학습하게 됨\n",
    "- 대상의 일반적인 특징을 학습하기 때문에 다른 영역으로의 확장에서도 뛰어난 성능을 보임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 YOLO v1\n",
    "\n",
    "#### 특징\n",
    "- 빠른 Detection 시간. 그러나 낮은 정확도 (그 뒤 SSD가 더 좋은 성능과 속도를 보였음)\n",
    "- 기존의 객체 탐지는 single window나 regional proposal methods 등을 통해 바운딩 박스를 잡은 후 탐지된 바운딩 박스에 대해 분류를 수행하는 two-stage detection였음<br>\n",
    " $\\rarr$ 파이프라인이 복잡하기 때문에 학습 및 예측, 최적화 느려진다는 단점 존재\n",
    "- YOLO v1은 하나의 컨볼루션 네트워크를 통해 대상의 위치와 클래스를 한번에 예측 가능한 one-stage detection임\n",
    "- 테두리 상자 조정(Bounding Box Coordinate)과 분류(Classification)을 동일 신경망 구조를 통해 동시에 실행하는 통합인식(Unified Detection)을 구현하는 것이 큰 특징\n",
    "\n",
    "#### Detection 과정\n",
    "1. input 이미지를 $S \\times S$ grid로 분할(논문에서는 7x7)\n",
    "2. grid cell 당 bounding box와 Class probability 예측  \n",
    "    - 각 그리드 셀은 bouding box $B$와 해당 box의 confidence score를 예측\n",
    "      - confidence score = $Pr(Object)*IoU$=객체가 존재할 확률과 IoU 값의 곱\n",
    "          - 해당 box가 객체를 얼마나 포함하는지, 그 정확도는 얼마인지 등 모델이 얼마나 신뢰 가능한지를 나타내는 점수\n",
    "          - box 내 객체가 존재하지 않으면 객체 존재 확률 $Pr(Object)$가 0이므로 confidence score=0\n",
    "      - 각 bounding box는 $x,y,w,h,confidence \\ score$로 구성($x,y$ : box 중심 좌표 / $w, h$ : box 너비, 높이)  \n",
    "    - 각 그리드 셀은 조건부 클래스 확률 $Pr(Class\\ i\\ | \\ Object)$을 예측\n",
    "      - 그리드 셀이 객체를 포함할 때, 해당 객체가 i번째 클래스일 확률\n",
    "      - 각 그리드 셀 당 확률값이 가장 큰 하나의 클래스만 예측\n",
    "3. NMS를 통해 최종 예측\n",
    "    <div style=\"text-align:center\">\n",
    "        <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPk0eC%2FbtryCDrvbhN%2FGjM4eCM2VFV5j9nHfOKI71%2Fimg.png\" width=50% height=50%>\n",
    "    </div>\n",
    "\n",
    "\n",
    "   - 최종 bounding box는 $S \\times S \\times (B*5+C)$텐서 형태로 표현\n",
    "     - (S X S grid cell 크기) x ((한 grid cell당 예측할 bounding box 개수 B)*5+(class 개수 C))\n",
    "     - 논문 예시로 클래스가 20개인 데이터셋에 대해 이미지를 그리드 셀 7x7 크기로 나누고, 한 그리드 셀당 box를 2개씩 예측하려고 한다면 (7x7)x(2*5+20) = 7x7x30 크기의 3차원 tensor\n",
    "\n",
    "\n",
    "#### 단점\n",
    "1. 작은 객체 탐지가 어려움\n",
    "    - Spatial contraint (공간적 제약) : 그리드 셀 하나당 객체를 하나만 검출할 수 있어서, 한 셀에 작은 객체가 여러개 모여 있는 경우, 여러 객체를 검출하는 것이 아니라 하나로만 봐야하기 때문에 제대로 검출하지 못하는 문제\n",
    "2. 새로운 aspect ratio에 대한 탐지가 어려움\n",
    "    - aspect ratio : bounding box의 가로세로 비율\n",
    "    - 예를 들어, 1:1, 1:2, 2:1 비율의 bounding box만 학습했는데, 3:1 비율의 box를 테스트하면 탐지 못함\n",
    "3. 손실함수 Sum of Square Error(SSE)가 Bounding Box 크기와 관계없이 가중치를 동일하게 취급한 문제를 해결하지 못함\n",
    "    - Bounding Box의 높이와 넓이에 루트를 취해서 크기 차이를 감소해 문제를 개선했지만, 가중치는 동일하게 주기 때문에 완전히 해결하지 못함.\n",
    "\n",
    "#### Design and Code\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./img/yolov1_number.png\" width=60% height=60%>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "class YoLo_v1(nn.Module):\n",
    "    def __init__(self, num_classes=20, num_bboxes=2):\n",
    "        super(YoLo_v1, self).__init__()\n",
    "\n",
    "        self.feature_size = 7\n",
    "        self.num_bboxes=num_bboxes\n",
    "        self.num_classes=num_classes\n",
    "        self.conv = nn.Sequential(\n",
    "\n",
    "            # 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=4),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # 3\n",
    "            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # 4\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # 5\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            # 6\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            # 7\n",
    "            Flatten(),\n",
    "            nn.Linear(in_features=7*7*1024, out_features=4096),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            # 8\n",
    "            nn.Linear(in_features=4096, out_features=(feature_size*feature_size*(5 * num_bboxes + num_classes))),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "            \n",
    "        self.init_weight(self.conv)\n",
    "        self.init_weight(self.fc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s, b, c = self.feature_size, self.num_bboxes, self.num_classes\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x = x.view(-1, s, s, (5 * b + c))\n",
    "        return x\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 YOLO v2\n",
    "\n",
    "#### 특징\n",
    "1. backbone network로 `DarkNet-19`를 사용함\n",
    "2. Convolutional with Anchor boxes\n",
    "   - YOLO v1은 각 cell별로 2개의 bounding box를 예측하여 총 98(=7x7x2)개의 bounding box를 예측함\n",
    "   - YOLO v2는 anchor box를 사용하여 보다 많은 수의 bounding box를 예측함\n",
    "3. Dimension Clusters\n",
    "   \n",
    "   <img src=\"./img/dimension cluster.png\" width=40% height=40%>\n",
    "   \n",
    "   - 더 좋은 조건으로 학습을 시작하기 위해 K-means Clustering 사용하여 최적의 anchor box 크기와 ratio를 정하도록 함\n",
    "   - Ground Truth box의 width, height 값을 사용하여 K-means clustering을 수행함\n",
    "   - 논문에서는 5개의 anchor box를 사용하는 것이 네트워크가 detection task를 보다 쉽게 학습할 수 있다고 함  \n",
    "4. Fine-Grained Features\n",
    "   \n",
    "      <img src=\"./img/fine-Grained.png\" width=40% height=40%>\n",
    "   \n",
    "\n",
    "   - YOLO v2는 최종적으로 13x13 크기의 feature map을 출력함. 이처럼 feature map의 크기가 작은 경우 큰 객체를 예측하기 용이한 반면 작은 객체는 예측하기 어렵다는 문제가 있음\n",
    "   - 이 문제를 해결하기 위해 마지막 pooling을 수행하기 전에 feature map을 추출하여 26x26x512 크기의 feature map을 얻은 후 feature map의 channel은 유지하면서 4개로 분할한 후 결합하여 13x13x2048 크기의 feature map을 얻는다. <br>이러한 feature map은 보다 작은 객체에 대한 정보를 함축하고 있음\n",
    "   - 이를 13x13x1024 feature map에 추가하여 13x13x3072 크기의 feature map을 얻는다.\n",
    "  \n",
    "5. Batch Normailzation\n",
    "   - 모든 conv layer 뒤에 batch normalization을 추가함\n",
    "6. High Resolution Classifier\n",
    "   - YOLO v1 모델은 DarkNet을 224x224 크기로 pre-train시켰지만 detection task 시에는 448x448 크기의 이미지를 입력으로 사용함. 이는 네트워크가 object detection task를 학습하면서 동시에 새로운 입력 이미지의 resolution에 적응해야 함을 의미함\n",
    "   - YOLO v2 모델은 처음부터 DarkNet을 448x448 크기로 pre-train 시켜 네트워크가 상대적으로 높은 해상도의 이미지에 적응할 시간을 제공함\n",
    "7. Multi-Scale Training\n",
    "   - YOLO v2 모델을 보다 강건하게 만들기 위해 다양한 입력 이미지를 사용하여 네트워크를 학습시킴\n",
    "   - 논문에서는 10 batch마다 입력 이미지의 크기를 랜덤하게 선택하여 학습하도록 설계함\n",
    "   - 모델은 이미지를 1/32배로 downsample시키기 때문에 입력 이미지 크기를 32배수 중에서 선택하도록 함. \n",
    "   - 320x320 크기의 이미지가 가장 작은 입력 이미지이며, 608x608 크기의 이미지가 입력될 수 있는 가장 큰 이미지임\n",
    "   - 이를 통해 네트워크는 다양한 크기의 이미지를 입력받을 수 있고, 속도와 정확도 사이의 trade-off를 제공\n",
    "   - 입력 이미지의 크기가 작은 경우 더 높은 FPS를 가지며, 입력 이미지의 크기가 큰 경우 더 높은 mAP 값을 가지게 됨\n",
    "\n",
    "#### YOLO v1 VS YOLO v2\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"./img/diff v1,v2.png\" width=40% height=40%>\n",
    "</div>\n",
    "\n",
    "#### Design and Code\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"./img/yolov2_number.png\" width=60% height=60%>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "class Yolo(nn.Module):\n",
    "    def __init__(self, num_classes,\n",
    "                 anchors=[(1.3221, 1.73145), (3.19275, 4.00944), (5.05587, 8.09892), (9.47112, 4.84053),\n",
    "                          (11.2364, 10.0071)]):\n",
    "        super(Yolo, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "\n",
    "        # 1\n",
    "        self.stage1_conv1 = nn.Sequential(nn.Conv2d(3, 32, 3, 1, 1, bias=False), nn.BatchNorm2d(32),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        \n",
    "        # 2\n",
    "        self.stage1_conv2 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 1, bias=False), nn.BatchNorm2d(64),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        \n",
    "        # 3\n",
    "        self.stage1_conv3 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1, bias=False), nn.BatchNorm2d(128),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv4 = nn.Sequential(nn.Conv2d(128, 64, 1, 1, 0, bias=False), nn.BatchNorm2d(64),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "         \n",
    "        # 4\n",
    "        self.stage1_conv5 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1, bias=False), nn.BatchNorm2d(128),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        self.stage1_conv6 = nn.Sequential(nn.Conv2d(128, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv7 = nn.Sequential(nn.Conv2d(256, 128, 1, 1, 0, bias=False), nn.BatchNorm2d(128),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv8 = nn.Sequential(nn.Conv2d(128, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        \n",
    "        # 5                           \n",
    "        self.stage1_conv9 = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv10 = nn.Sequential(nn.Conv2d(512, 256, 1, 1, 0, bias=False), nn.BatchNorm2d(256),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv11 = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        # 6                              \n",
    "        self.stage1_conv12 = nn.Sequential(nn.Conv2d(512, 256, 1, 1, 0, bias=False), nn.BatchNorm2d(256),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv13 = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        # 7\n",
    "        self.stage2_a_maxpl = nn.MaxPool2d(2, 2)\n",
    "        self.stage2_a_conv1 = nn.Sequential(nn.Conv2d(512, 1024, 3, 1, 1, bias=False),\n",
    "                                            nn.BatchNorm2d(1024), nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv2 = nn.Sequential(nn.Conv2d(1024, 512, 1, 1, 0, bias=False), nn.BatchNorm2d(512),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv3 = nn.Sequential(nn.Conv2d(512, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "      \n",
    "        # 8\n",
    "        self.stage2_a_conv4 = nn.Sequential(nn.Conv2d(1024, 512, 1, 1, 0, bias=False), nn.BatchNorm2d(512),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv5 = nn.Sequential(nn.Conv2d(512, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv6 = nn.Sequential(nn.Conv2d(1024, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv7 = nn.Sequential(nn.Conv2d(1024, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        # 11\n",
    "        self.stage3_conv1 = nn.Sequential(nn.Conv2d(2048 + 1024, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage3_conv2 = nn.Conv2d(1024, len(self.anchors) * (5 + num_classes), 1, 1, 0, bias=False)\n",
    "\n",
    "   def forward(self, input):\n",
    "        # 1\n",
    "        output = self.stage1_conv1(input)\n",
    "\n",
    "        # 2\n",
    "        output = self.stage1_conv2(output)\n",
    "\n",
    "        # 3\n",
    "        output = self.stage1_conv3(output)\n",
    "        output = self.stage1_conv4(output)\n",
    "\n",
    "        # 4\n",
    "        output = self.stage1_conv5(output)\n",
    "        output = self.stage1_conv6(output)\n",
    "        output = self.stage1_conv7(output)\n",
    "        output = self.stage1_conv8(output)\n",
    "\n",
    "        # 5\n",
    "        output = self.stage1_conv9(output)\n",
    "        output = self.stage1_conv10(output)\n",
    "        output = self.stage1_conv11(output)\n",
    "\n",
    "        # 6\n",
    "        output = self.stage1_conv12(output)\n",
    "        output = self.stage1_conv13(output)\n",
    "\n",
    "        residual = output # 6번 과정이 끝난 후 결과를 저장\n",
    "        \n",
    "        # 7\n",
    "        output_1 = self.stage2_a_maxpl(output)\n",
    "        output_1 = self.stage2_a_conv1(output_1)\n",
    "        output_1 = self.stage2_a_conv2(output_1)\n",
    "        output_1 = self.stage2_a_conv3(output_1)\n",
    "\n",
    "        # 8\n",
    "        output_1 = self.stage2_a_conv4(output_1)\n",
    "        output_1 = self.stage2_a_conv5(output_1)\n",
    "        output_1 = self.stage2_a_conv6(output_1)\n",
    "        output_1 = self.stage2_a_conv7(output_1)\n",
    "        \n",
    "        # 9, 26x26x512 => 13x13x2048\n",
    "        output_2 = residual\n",
    "        batch_size, num_channel, height, width = output_2.data.size()\n",
    "        output_2 = output_2.view(batch_size, int(num_channel / 4), height, 2, width, 2).contiguous()\n",
    "        output_2 = output_2.permute(0, 3, 5, 1, 2, 4).contiguous()\n",
    "        output_2 = output_2.view(batch_size, -1, int(height / 2), int(width / 2))\n",
    "\n",
    "        # 10\n",
    "        output = torch.cat((output_1, output_2), 1)\n",
    "        \n",
    "        # 11\n",
    "        output = self.stage3_conv1(output)\n",
    "        output = self.stage3_conv2(output)\n",
    "\n",
    "        return output\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 YOLO v3\n",
    "\n",
    "#### Design\n",
    "<img src=\"https://postfiles.pstatic.net/MjAyMDAzMTNfMzcg/MDAxNTg0MDY3NjEyMzY4.d2fCI9WlzwaezCH3nM13-iKcLfpeyGSO9kWpPmBHzZ0g.sYbPMGPLqdGw-JDcrmNHmNzjQEFb7L-8f8IjXqXxNB4g.PNG.polpolie95/image.png?type=w966\" width=40% height=40%>\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/162982/Torch_Yolo_V3_feature_map.png\" width=70% height=70%>\n",
    "\n",
    "\n",
    "#### 특징\n",
    "- FPN와 유사한 기법을 적용하여 3개의 Feature Map Output에서(13x13, 26x26, 52x52), 각각 3개의 서로 다른 크기의 scale을 가진 anchor box로 Detection\n",
    "- DarkNet-53을 통해서 좀 더 강한 Semantic한 Feature Map 추출\n",
    "- Multi Labels을 예측하기 위해 Softmax가 아닌 Sigmoid 기반의 Logistic Regression Classifier로 개별 Object의 Multi labels 예측\n",
    "- 수행 속도는 YOLO v2보다 줄었지만 수행 성능은 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 YOLO v4\n",
    "\n",
    "#### Design\n",
    "\n",
    "<img src=\"./img/yolov4.png\" width=40% height=40%>\n",
    "\n",
    "\n",
    "- `Backbone` : CSPDarkNet-53 <br> 입력 이미지로부터 다양한 feature를 추출하는 역할을 함\n",
    "- `Neck` : SPP(Spatial Pyramid Pooling)+PAN(Path Aggregation Network) <br> `backbone`에서 나온 결과(feature map)를 `head`로 전달하기 전에 refinement(정제), reconfiguration(재구성)함\n",
    "- `Head` : YOLO v3 <br> bounding box 및 class 예측을 만드는 네트워크의 일부\n",
    "- Bag of Freebies for backbone : CutMix, Mosaic, DropBlock, Class label smoothing\n",
    "- Bag of Specials for backbone : Mish, CSP, Muiti-input weighted residual connections(MiWRC)\n",
    "- Bag of Freebies for detector : CIoU, CmBN, DropBlock, Mosaic, Self Adversarial Training, Eliminate grid sensitivity, Using multiple anchors for a single ground truth, Cosine anneling scheduler, Optimal hyper parameters, Random training shapes\n",
    "- Bag of Specials for detector : Mish, SPP, SAM, PAN, DIoU NMS\n",
    "\n",
    "    * Bag of Freebies : 모델의 inference 시간을 늘리지 않으면서 더 높은 정확도를 얻을 수 있도록 학습시키는 방법(Data Augmentation, Semantic distribution bias, Objective function of Bounding box regression 등)\n",
    "    * Bag of Special : inference 시 cost를 아주 조금 증가시키지만 정확도를 크게 향상시킬 수 있는 추가 모듈 혹은 post-processing 방법을 말함(Enhance receptive field, Attention module, Feature integration, Activation function, post-processing method 등)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/163049/Object_Detection_Flow_Yolov4_Architecture.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/163565/Torch_Yolo_V4_feature_map.png\" width=\"70%\" height=\"70%\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c585f91d3623973be3accc48b0d5e967ce904a396a0f0c8bda7b100d8b60333f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
